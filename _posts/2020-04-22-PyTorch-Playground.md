---
keywords: fastai
description: a little-more-than-introductory guide to help people get comfortable with PyTorch functionalities
title: PyTorch Playground
toc: true 
badges: true
comments: true
author: Aditya Rana
image: images/pytorch_meme.png
categories: [tutorials]
nb_path: _notebooks/2020-04-22-PyTorch-Playground.ipynb
layout: notebook
---

<!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-04-22-PyTorch-Playground.ipynb
-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>{% include image.html height="300" max-width="300" file="/blog/images/copied_from_nb/images/pytorch-logo-dark.png" %}</p>
<h2 id="Dataset-and-Transforms">Dataset and Transforms<a class="anchor-link" href="#Dataset-and-Transforms"> </a></h2><ul>
<li>Dataset Class : manages the data, labels and data augmentations</li>
<li>DataLoader Class : manages the size of the minibatch </li>
</ul>
<h3 id="Creating-your-Own-Dataset">Creating your Own Dataset<a class="anchor-link" href="#Creating-your-Own-Dataset"> </a></h3><p>Let's take the example of training an autoencoder in which our training data only consists of images.</p>
<p>{% include image.html file="/blog/images/copied_from_nb/images/autoencoder_mnist.png" %}</p>
<p>The encoder can be made up of convolutional or linear layers.</p>
<p>{% include image.html height="400" max-width="400" file="/blog/images/copied_from_nb/images/autoencoder.png" %}</p>
<p>To create our own dataset class in PyTorch we inherit from the torch.utils.data.Dataset class and define two main methods, the <code>__len__</code> and the <code>__getitem__</code></p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">transforms</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span>

<span class="k">class</span> <span class="nc">ImageDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A class for creating data and augemntation pipeline</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">glob_pattern</span><span class="p">:</span><span class="nb">str</span><span class="p">,</span> <span class="n">patchsize</span><span class="p">:</span><span class="nb">int</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        glob_pattern: this pattern must expand </span>
<span class="sd">            to a list of RGB images in PNG format. </span>
<span class="sd">            For eg. &quot;/data/train/cat/*.png&quot;</span>
<span class="sd">            </span>
<span class="sd">        patchsize: the size you want to crop</span>
<span class="sd">            the image to</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">image_paths_list</span> <span class="o">=</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="n">glob_pattern</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">patchsize</span> <span class="o">=</span> <span class="n">patchsize</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># denotes size of data</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">image_paths_list</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">image</span><span class="p">):</span>
        <span class="c1"># convert to RGB if image is B/W</span>
        <span class="k">if</span> <span class="n">image</span><span class="o">.</span><span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;L&#39;</span><span class="p">:</span>
            <span class="n">image</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="s1">&#39;RGB&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data_transforms</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span><span class="n">transforms</span><span class="o">.</span><span class="n">RandomCrop</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">patchsize</span><span class="p">),</span>
                                                   <span class="n">transforms</span><span class="o">.</span><span class="n">RandomHorizontalFlip</span><span class="p">(),</span>
                                                   <span class="n">transforms</span><span class="o">.</span><span class="n">RandomVerticalFlip</span><span class="p">(),</span>
                                                   <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">()])</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">data_transforms</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
        <span class="c1"># generates one sample of data</span>
        <span class="n">image</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">image_paths</span><span class="p">[</span><span class="n">index</span><span class="p">])</span>
        <span class="n">image</span><span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">image</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Transforms">Transforms<a class="anchor-link" href="#Transforms"> </a></h3><p>Image processing operations using torchvision.transforms like cropping and resizing are done on the PIL Images and then they are converted to Tensors. The last transform which is transforms.ToTensor() seperates the the PIL Image into 3 channels (R,G,B) and scales its elements to the range (0,1).</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>A transform one observes a lot in Computer Vision based data pipelines is data normalization.</p>
<div class="highlight"><pre><span></span><span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">],</span>
                     <span class="n">std</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">])</span>
</pre></div>
<p>If you're wondering where do these mean and std values come from, the answer is, the <a href="http://www.image-net.org/">ImageNet dataset</a>. It's a huge dataset of 14 million images and most pre-trained models are originally trained on this. The above values are the channel-wise mean and std of all the images in the dataset. So whenever you import a pre-trained model from torchvision, make sure you apply the normalization based on the statistics of the dataset that the model was trained on. Hence, the pipeline can be summarized as</p>

<pre><code>Image --&gt; Crop/Resize --&gt; toTensor --&gt; Normalize

</code></pre>
<p>To read more about why we normalize our data, read my blog post on this <a href="https://adityassrana.github.io/blog/theory/2020/08/26/Weight-Init.html">here</a></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Tranforms-functional-API">Tranforms functional API<a class="anchor-link" href="#Tranforms-functional-API"> </a></h3><p>The functional API is stateless and you can directly pass all the necessary arguments. Whereas torchvision.transforms are classes initialized with some default parameters unless specified.</p>
<div class="highlight"><pre><span></span><span class="c1"># Class-based. Define once and use multiple times</span>
<span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span> <span class="n">std</span><span class="o">=</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">))</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="c1"># Functional. Pass parameters each time</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">TF</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span> <span class="n">std</span><span class="o">=</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">))</span>
</pre></div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The functional API is very useful when transforming your data and target with the same random values, e.g. random cropping</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torchvision.transforms.functional</span> <span class="k">as</span> <span class="nn">TF</span> <span class="c1">#it&#39;s not tensorflow :p</span>
<span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">RandomCrop</span><span class="o">.</span><span class="n">get_params</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">output_size</span><span class="o">=</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">))</span>
<span class="n">image</span> <span class="o">=</span> <span class="n">TF</span><span class="o">.</span><span class="n">crop</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span>
<span class="n">mask</span> <span class="o">=</span> <span class="n">TF</span><span class="o">.</span><span class="n">crop</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>It also allows us to perform identical transforms on both image and target</p>
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">image</span><span class="p">,</span> <span class="n">mask</span><span class="p">):</span>
    <span class="c1"># Resize</span>
    <span class="n">resize</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">520</span><span class="p">,</span> <span class="mi">520</span><span class="p">))</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">resize</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">resize</span><span class="p">(</span><span class="n">mask</span>

<span class="c1"># Random horizontal flipping</span>
<span class="k">if</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">:</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">TF</span><span class="o">.</span><span class="n">hflip</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">TF</span><span class="o">.</span><span class="n">hflip</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>

<span class="c1"># Random vertical flipping</span>
<span class="k">if</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">:</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">TF</span><span class="o">.</span><span class="n">vflip</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">TF</span><span class="o">.</span><span class="n">vflip</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="DataLoaders">DataLoaders<a class="anchor-link" href="#DataLoaders"> </a></h3><p>The data is passed to the model few samples at a time as datasets are usually too big to fit entirely on the CPU/GPU.</p>
<p>For choosing an appropriate batch_size, make it as high as possible as long as you dont encounter <code>RuntimeError: CUDA out of memory</code> and as long as it's a multiple of 16.</p>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span>
                          <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span>
                          <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
                          <span class="n">num_workers</span> <span class="o">=</span> <span class="mi">4</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Data-Augmentation,-where-does-it-happen?">Data Augmentation, where does it happen?<a class="anchor-link" href="#Data-Augmentation,-where-does-it-happen?"> </a></h3><p>A lot of people get confused about how data augmentation helps in increasing the size of the dataset when we're not actually creating or saving new images. The point to understand here is that data augmentation happens on the fly. Every time <code>__getitem__</code> method in the Dataset Class is called by the DataLoader, the transformations are applied.</p>
<p>When you  use the dataloader in your training loop, at the start of every epoch it supplies a new data-augemnted dataset with the augmentations applied to each element. This means at each epoch, the model will see a new variant of the dataset.</p>
<div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">():</span>
</pre></div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Kornia">Kornia<a class="anchor-link" href="#Kornia"> </a></h3><p>Another thing to note is that these operations are performed on the CPU so you need to make sure that your data processing does not become your training bottleneck when using large batchsizes. This is the time for introducing -</p>
<p>{% include image.html height="300" max-width="300" file="/blog/images/copied_from_nb/images/kornia_logo.svg" %}</p>
<p><a href="https://github.com/kornia/kornia">Kornia</a> is a differentiable computer vision library for PyTorch that operates directly on tensors, hence letting you make full use of your GPUs.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Writing-Custom-Autograd-Functions-/-Layers">Writing Custom Autograd Functions / Layers<a class="anchor-link" href="#Writing-Custom-Autograd-Functions-/-Layers"> </a></h2><h3 id="Writing-your-own-ReLU">Writing your own ReLU<a class="anchor-link" href="#Writing-your-own-ReLU"> </a></h3><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MyReLU</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">Function</span><span class="p">):</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span class="n">i</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; </span>
<span class="sd">        ctx is a context object that can be used</span>
<span class="sd">        to stash information for backward computation. </span>
<span class="sd">        You can cache arbitrary objects for use in the </span>
<span class="sd">        backward pass using the ctx.save_for_backward method.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">input</span> <span class="o">=</span> <span class="n">i</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="n">ctx</span><span class="o">.</span><span class="n">save_for_backward</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">input</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        In the backward pass we receive a Tensor </span>
<span class="sd">        containing the gradient of the loss wrt </span>
<span class="sd">        the output, and we need to compute the gradient </span>
<span class="sd">        of the loss wrt the input.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">input</span><span class="p">,</span> <span class="o">=</span> <span class="n">ctx</span><span class="o">.</span><span class="n">saved_tensors</span>
        <span class="n">grad_input</span> <span class="o">=</span> <span class="n">grad_output</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="n">grad_input</span><span class="p">[</span><span class="nb">input</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">return</span> <span class="n">grad_input</span>
</pre></div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Understanding-Gradient-Shape">Understanding Gradient Shape<a class="anchor-link" href="#Understanding-Gradient-Shape"> </a></h3><p>{% include image.html height="500" max-width="500" file="/blog/images/copied_from_nb/images/local_gradients_backprop.png" %}</p>
<p>Gradient returned by the backward method of the class should have the same shape as the input to the forward method of the class, so that the gradient computed for the input after the loss.backward() step has the same shape as input and can be used to update it in the optimizer.step()</p>
<p>loss.backward() computes d(loss)/d(w) for every parameter which has requires_grad=True. They are accumulated in w.grad. And the optimizer.step() updates w using w.grad, w += -lr* x.grad</p>
<p>For more info read the posts below</p>
<ul>
<li><a href="https://adityassrana.github.io/blog/programming/pytorch/2020/09/25/Modern-PyTorch.html#Custom-Layers">PyTorch Custom Layers</a></li>
<li><a href="https://github.com/pytorch/pytorch/blob/53fe804322640653d2dddaed394838b868ce9a26/torch/autograd/_functions/pointwise.py">PyTorch Source Code Examples on Github</a></li>
<li><a href="https://pytorch.org/tutorials/beginner/examples_autograd/two_layer_net_custom_function.html">PyTorch official docs</a></li>
</ul>
<p>Avoid using in-place operations as they cause problems while back-propagation because of the way they modify the graph. As a precaution, always clone the input in the forward pass, and clone the incoming gradients before modifying them.</p>
<p>An in-place operation directly modifies the content of a given Tensor without making a copy. Inplace operations in PyTorch are always postfixed with a <em>, like .add</em>() or .scatter_(). Python operations like + = or *= are also in-place operations.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Dealing-with-non-differentiable-functions">Dealing with non-differentiable functions<a class="anchor-link" href="#Dealing-with-non-differentiable-functions"> </a></h3><p>Sometimes in your model or loss calculation you need to use functions that are non-differentiable. For calculating gradients, autograd requires all components of the graph to be differentiable. You can work around this by using a proxy function in the backward pass calculations.</p>

<pre><code>f_hard : non-differentiable
f_soft : differentiable proxy for w_hard

</code></pre>
<div class="highlight"><pre><span></span><span class="n">f_out</span> <span class="o">=</span> <span class="n">f_soft</span> <span class="o">+</span> <span class="p">(</span><span class="n">f_hard</span> <span class="o">-</span> <span class="n">f_soft</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>  <span class="c1"># in PyTorch</span>
<span class="n">f_out</span> <span class="o">=</span> <span class="n">f_soft</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">stop_grad</span><span class="p">(</span><span class="n">f_hard</span> <span class="o">-</span> <span class="n">f_soft</span><span class="p">)</span> <span class="c1"># in Tensorflow</span>
</pre></div>
<h3 id="Core-Idea">Core Idea<a class="anchor-link" href="#Core-Idea"> </a></h3>
<pre><code>y = x_backward + (x_forward - x_backward).detach()</code></pre>
<p>It gets you x_forward in the forward pass, but derivative acts as if you had x_backward</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Example">Example<a class="anchor-link" href="#Example"> </a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Binarizer</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">Function</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    An elementwise function that bins values</span>
<span class="sd">    to 0 or 1 depending on a threshold of 0.5,</span>
<span class="sd">    but in backward pass acts as an identity layer.</span>

<span class="sd">    Such layers are also known as </span>
<span class="sd">    straight-through gradient estimators</span>

<span class="sd">    Input: a tensor with values in range (0,1)</span>
<span class="sd">    Returns: a tensor with binary values: 0 or 1</span>
<span class="sd">    based on a threshold of 0.5</span>
<span class="sd">    Equation(1) in paper</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span class="n">i</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">i</span><span class="o">&gt;</span><span class="mf">0.5</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">grad_output</span>

<span class="k">def</span> <span class="nf">bin_values</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">Binarizer</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The above function can be reimplemented with a single line in Pytorch
while maintaining differentiabilty</p>
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">bin_values</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">+</span> <span class="p">((</span><span class="n">x</span><span class="o">&gt;</span><span class="mf">0.5</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span> <span class="o">-</span> <span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Basic-Training-and--Validation-Loop">Basic Training and  Validation Loop<a class="anchor-link" href="#Basic-Training-and--Validation-Loop"> </a></h2><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">loss_func</span><span class="p">,</span> <span class="n">opt</span><span class="p">,</span> <span class="n">train_dl</span><span class="p">,</span> <span class="n">valid_dl</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="c1"># Handle batchnorm / dropout</span>
        <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        <span class="c1"># print(model.training)</span>
        <span class="k">for</span> <span class="n">mini_batch</span> <span class="ow">in</span> <span class="n">train_dl</span><span class="p">:</span>
            <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">mini_batch</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_func</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

        <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="c1">#print(model.training)</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="k">for</span> <span class="n">mini_batch</span> <span class="ow">in</span> <span class="n">valid_dl</span><span class="p">:</span>
                <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">mini_batch</span><span class="p">)</span>
                <span class="c1"># log some metrics here</span>
            <span class="c1"># aggregate metrics from all batches</span>
</pre></div>
<p>Once you become more familiar with writing training and validation loops, I would recommend you to try out PyTorch Lightning <a href="https://github.com/PyTorchLightning/pytorch-lightning">PyTorch Lightning</a> , which is a great library started by <a href="https://www.williamfalcon.com/">William Falcon</a> that helps you get rid of all the PyTorch boilerplate code and instead lets you focus on the research part of your project.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Tensorboard">Tensorboard<a class="anchor-link" href="#Tensorboard"> </a></h2><h3 id="Installing">Installing<a class="anchor-link" href="#Installing"> </a></h3><p>Install tensorboard with <code>pip install tensorboard</code></p>
<p>{% include image.html file="/blog/images/copied_from_nb/images/tensorboard.gif" %}</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Creating-a-SummaryWriter">Creating a SummaryWriter<a class="anchor-link" href="#Creating-a-SummaryWriter"> </a></h3><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch.utils.tensorboard</span> <span class="kn">import</span> <span class="n">SummaryWriter</span>
<span class="n">writer_train</span> <span class="o">=</span> <span class="n">SummaryWriter</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">experiment_dir</span><span class="p">,</span><span class="s2">&quot;tensorboard&quot;</span><span class="p">))</span>
<span class="err">`</span>
</pre></div>
<h3 id="Scalars">Scalars<a class="anchor-link" href="#Scalars"> </a></h3><p>Logging statements are added at different steps in the training loop wherever you want to log something. You can track scalars, images and even histograms. You can read more about this on the official <a href="https://pytorch.org/docs/stable/tensorboard.html">PyTorch docs</a></p>
<p>Logging scalars can be as simple as</p>
<div class="highlight"><pre><span></span><span class="n">writer_train</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="s1">&#39;train_loss&#39;</span><span class="p">,</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">iteration</span><span class="p">)</span>
</pre></div>
<p>where iteration is the global_step_count that you can keep track of inside your training loop.</p>
<h3 id="Images">Images<a class="anchor-link" href="#Images"> </a></h3><p>We'll use <code>make_grid</code> to create a grid of images directly from tensors so that we can plot them together.</p>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torchvision.utils</span> <span class="kn">import</span> <span class="n">make_grid</span>

<span class="c1"># x is a tensor of Images of the shape (N,3,H,W)</span>
<span class="n">x_grid</span> <span class="o">=</span> <span class="n">make_grid</span><span class="p">(</span><span class="n">x</span><span class="p">[:</span><span class="mi">5</span><span class="p">],</span><span class="n">nrow</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">writer_train</span><span class="o">.</span><span class="n">add_image</span><span class="p">(</span><span class="s1">&#39;train/original_images&#39;</span><span class="p">,</span><span class="n">x_grid</span><span class="p">,</span> <span class="n">iteration</span><span class="p">)</span>
</pre></div>
<h3 id="Launch">Launch<a class="anchor-link" href="#Launch"> </a></h3><p>To visualize what you've logged, launch a tensorboard instance from the terminal by entering <code>tensorboard --logdir .</code> in the directory where you have logged your experiments.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Inference">Inference<a class="anchor-link" href="#Inference"> </a></h2><p>To make predictions out of your trained model, make sure you feed data in the right format.</p>
<p>Input Tensor Format : (batch_size, channels, height, width). The model and the convolutional layers expect the input tensor to be of the shape (N,C,H,W), so when feeding an image/images to the model, add a dimension for batching.</p>
<p>Converting from img--&gt;numpy representation and feeding the model gives an error because the input is in ByteTensor format. Only float operations are supported for conv-like operations. So add an extra step after numpy conversion -</p>
<div class="highlight"><pre><span></span><span class="n">img</span> <span class="o">=</span> <span class="n">img</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="s1">&#39;torch.DoubleTensor&#39;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Saving-and-Loading-Models">Saving and Loading Models<a class="anchor-link" href="#Saving-and-Loading-Models"> </a></h2><p>PyTorch saves a model as a state_dict and the extension used is .pt</p>
<div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">PATH</span> <span class="o">=</span> <span class="s1">&#39;latest_checkpoint.pt&#39;</span><span class="p">)</span>
</pre></div>
<p>Sometimes you add new layers to your model which which were not present in the model you saved as checkpoint. In such a case set the <code>strict</code> keyword to False</p>
<div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">()</span>
<span class="n">checkpoint</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;latest_checkpoint.pt&#39;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">,</span> <span class="n">strict</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
<p>On Loading a model, if it shows a message like this, it means there were no missing keys and everything went well ( it's not an error ).</p>

<pre><code>IncompatibleKeys(missing_keys=[], unexpected_keys=[])</code></pre>
<p>Keyboard interrupt and saving the last state of a model if you need to stop the experiment mid-way of training:</p>
<div class="highlight"><pre><span></span><span class="k">try</span><span class="p">:</span>
    <span class="c1"># training code here</span>
<span class="k">except</span> <span class="ne">KeyboardInterrupt</span><span class="p">:</span>
    <span class="c1"># save model here</span>
</pre></div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Extra-Resources">Extra Resources<a class="anchor-link" href="#Extra-Resources"> </a></h2><ul>
<li><a href="https://github.com/Kaixhin/grokking-pytorch/blob/master/README.md">Grokking PyTorch</a></li>
<li><a href="https://github.com/vahidk/EffectivePyTorch/blob/master/README.md">Effective PyTorch</a></li>
<li><a href="https://amitness.com/2020/03/python-magic-behind-pytorch">The Python Magic Behind PyTorch</a></li>
<li><a href="https://github.com/chiphuyen/python-is-cool/blob/master/README.md">Python is Cool - ChipHuyen</a></li>
<li><a href="https://github.com/IgorSusmelj/pytorch-styleguide/blob/master/README.md">PyTorch StyleGuide</a></li>
<li><a href="https://github.com/zedr/clean-code-python">Clean Code Python</a></li>
<li><a href="https://dbader.org/blog/meaning-of-underscores-in-python">Using _ in Variable Naming</a></li>
<li><a href="https://discuss.pytorch.org/t/pytorch-coding-conventions/42548">Pytorch Coding Conventions</a></li>
<li><a href="https://spandan-madan.github.io/A-Collection-of-important-tasks-in-pytorch/">Fine Tuning etc</a></li>
<li><a href="https://github.com/dsgiitr/d2l-pytorch">https://github.com/dsgiitr/d2l-pytorch</a></li>
<li><a href="https://github.com/L1aoXingyu/pytorch-beginner">https://github.com/L1aoXingyu/pytorch-beginner</a></li>
<li><a href="https://github.com/yunjey/pytorch-tutorial">https://github.com/yunjey/pytorch-tutorial</a></li>
<li><a href="https://github.com/MorvanZhou/PyTorch-Tutorial">https://github.com/MorvanZhou/PyTorch-Tutorial</a></li>
</ul>

</div>
</div>
</div>
</div>
 


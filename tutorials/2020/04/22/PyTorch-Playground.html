<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>PyTorch Playground | Aditya Rana Blog</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="PyTorch Playground" />
<meta name="author" content="Aditya Rana" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="a little-more-than-introductory guide to help people get comfortable with PyTorch functionalities" />
<meta property="og:description" content="a little-more-than-introductory guide to help people get comfortable with PyTorch functionalities" />
<link rel="canonical" href="https://adityassrana.github.io/blog/tutorials/2020/04/22/PyTorch-Playground.html" />
<meta property="og:url" content="https://adityassrana.github.io/blog/tutorials/2020/04/22/PyTorch-Playground.html" />
<meta property="og:site_name" content="Aditya Rana Blog" />
<meta property="og:image" content="https://adityassrana.github.io/blog/images/pytorch_meme.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-04-22T00:00:00-05:00" />
<script type="application/ld+json">
{"author":{"@type":"Person","name":"Aditya Rana"},"description":"a little-more-than-introductory guide to help people get comfortable with PyTorch functionalities","@type":"BlogPosting","headline":"PyTorch Playground","dateModified":"2020-04-22T00:00:00-05:00","datePublished":"2020-04-22T00:00:00-05:00","url":"https://adityassrana.github.io/blog/tutorials/2020/04/22/PyTorch-Playground.html","image":"https://adityassrana.github.io/blog/images/pytorch_meme.png","mainEntityOfPage":{"@type":"WebPage","@id":"https://adityassrana.github.io/blog/tutorials/2020/04/22/PyTorch-Playground.html"},"@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/blog/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://adityassrana.github.io/blog/feed.xml" title="Aditya Rana Blog" /><!-- the google_analytics_id gets auto inserted from the config file -->



<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-6G1KTP71W3"></script>
<script>
  window['ga-disable-G-6G1KTP71W3'] = window.doNotTrack === "1" || navigator.doNotTrack === "1" || navigator.doNotTrack === "yes" || navigator.msDoNotTrack === "1";
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-6G1KTP71W3');
</script>


<link rel="icon" type="image/png" href=/blog/images/twowolves.png><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>PyTorch Playground | Aditya Rana Blog</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="PyTorch Playground" />
<meta name="author" content="Aditya Rana" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="a little-more-than-introductory guide to help people get comfortable with PyTorch functionalities" />
<meta property="og:description" content="a little-more-than-introductory guide to help people get comfortable with PyTorch functionalities" />
<link rel="canonical" href="https://adityassrana.github.io/blog/tutorials/2020/04/22/PyTorch-Playground.html" />
<meta property="og:url" content="https://adityassrana.github.io/blog/tutorials/2020/04/22/PyTorch-Playground.html" />
<meta property="og:site_name" content="Aditya Rana Blog" />
<meta property="og:image" content="https://adityassrana.github.io/blog/images/pytorch_meme.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-04-22T00:00:00-05:00" />
<script type="application/ld+json">
{"author":{"@type":"Person","name":"Aditya Rana"},"description":"a little-more-than-introductory guide to help people get comfortable with PyTorch functionalities","@type":"BlogPosting","headline":"PyTorch Playground","dateModified":"2020-04-22T00:00:00-05:00","datePublished":"2020-04-22T00:00:00-05:00","url":"https://adityassrana.github.io/blog/tutorials/2020/04/22/PyTorch-Playground.html","image":"https://adityassrana.github.io/blog/images/pytorch_meme.png","mainEntityOfPage":{"@type":"WebPage","@id":"https://adityassrana.github.io/blog/tutorials/2020/04/22/PyTorch-Playground.html"},"@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

<link href="https://unpkg.com/@primer/css/dist/primer.css" rel="stylesheet" />
<link rel="stylesheet" href="//use.fontawesome.com/releases/v5.0.7/css/all.css"><link type="application/atom+xml" rel="alternate" href="https://adityassrana.github.io/blog/feed.xml" title="Aditya Rana Blog" /><!-- the google_analytics_id gets auto inserted from the config file -->



<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-6G1KTP71W3"></script>
<script>
  window['ga-disable-G-6G1KTP71W3'] = window.doNotTrack === "1" || navigator.doNotTrack === "1" || navigator.doNotTrack === "yes" || navigator.msDoNotTrack === "1";
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-6G1KTP71W3');
</script>



    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"> </script>
    <script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/blog/"> <img src= "/blog/images/twowolves.png" width="40"> Aditya Rana Blog </a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/blog/about">About Me</a><a class="page-link" href="/blog/resources/">Resources</a><a class="page-link" href="/blog/archive/">Archive</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">PyTorch Playground</h1><p class="page-description">a little-more-than-introductory guide to help people get comfortable with PyTorch functionalities</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-04-22T00:00:00-05:00" itemprop="datePublished">
        Apr 22, 2020
      </time>• 
          <span itemprop="author" itemscope itemtype="http://schema.org/Person">
            <span class="p-author h-card" itemprop="name">Aditya Rana</span></span>
       • <span class="read-time" title="Estimated read time">
    
    
      9 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/blog/categories/#tutorials">tutorials</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">

    <a href="https://github.com/adityassrana/blog/tree/master/_notebooks/2020-04-22-PyTorch-Playground.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/blog/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/adityassrana/blog/master?filepath=_notebooks%2F2020-04-22-PyTorch-Playground.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/blog/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/adityassrana/blog/blob/master/_notebooks/2020-04-22-PyTorch-Playground.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/blog/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h2"><a href="#Dataset-and-Transforms">Dataset and Transforms </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Creating-your-Own-Dataset">Creating your Own Dataset </a></li>
<li class="toc-entry toc-h3"><a href="#Transforms">Transforms </a></li>
<li class="toc-entry toc-h3"><a href="#Tranforms-functional-API">Tranforms functional API </a></li>
<li class="toc-entry toc-h3"><a href="#DataLoaders">DataLoaders </a></li>
<li class="toc-entry toc-h3"><a href="#Data-Augmentation,-where-does-it-happen?">Data Augmentation, where does it happen? </a></li>
<li class="toc-entry toc-h3"><a href="#Kornia">Kornia </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#Writing-Custom-Autograd-Functions-/-Layers">Writing Custom Autograd Functions / Layers </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Writing-your-own-ReLU">Writing your own ReLU </a></li>
<li class="toc-entry toc-h3"><a href="#Understanding-Gradient-Shape">Understanding Gradient Shape </a></li>
<li class="toc-entry toc-h3"><a href="#Dealing-with-non-differentiable-functions">Dealing with non-differentiable functions </a></li>
<li class="toc-entry toc-h3"><a href="#Core-Idea">Core Idea </a></li>
<li class="toc-entry toc-h3"><a href="#Example">Example </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#Basic-Training-and--Validation-Loop">Basic Training and  Validation Loop </a></li>
<li class="toc-entry toc-h2"><a href="#Tensorboard">Tensorboard </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Installing">Installing </a></li>
<li class="toc-entry toc-h3"><a href="#Creating-a-SummaryWriter">Creating a SummaryWriter </a></li>
<li class="toc-entry toc-h3"><a href="#Scalars">Scalars </a></li>
<li class="toc-entry toc-h3"><a href="#Images">Images </a></li>
<li class="toc-entry toc-h3"><a href="#Launch">Launch </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#Inference">Inference </a></li>
<li class="toc-entry toc-h2"><a href="#Saving-and-Loading-Models">Saving and Loading Models </a></li>
<li class="toc-entry toc-h2"><a href="#Extra-Resources">Extra Resources </a></li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-04-22-PyTorch-Playground.ipynb
-->

<div class="container" id="notebook-container">
        
    
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><figure>
  
    <img class="docimage" src="/blog/images/copied_from_nb/images/pytorch-logo-dark.png" alt="" style="max-width: 300px">
    
    
</figure>
</p>
<h2 id="Dataset-and-Transforms">
<a class="anchor" href="#Dataset-and-Transforms" aria-hidden="true"><span class="octicon octicon-link"></span></a>Dataset and Transforms<a class="anchor-link" href="#Dataset-and-Transforms"> </a>
</h2>
<ul>
<li>Dataset Class : manages the data, labels and data augmentations</li>
<li>DataLoader Class : manages the size of the minibatch </li>
</ul>
<h3 id="Creating-your-Own-Dataset">
<a class="anchor" href="#Creating-your-Own-Dataset" aria-hidden="true"><span class="octicon octicon-link"></span></a>Creating your Own Dataset<a class="anchor-link" href="#Creating-your-Own-Dataset"> </a>
</h3>
<p>Let's take the example of training an autoencoder in which our training data only consists of images.</p>
<p><figure>
  
    <img class="docimage" src="/blog/images/copied_from_nb/images/autoencoder_mnist.png" alt="">
    
    
</figure>
</p>
<p>The encoder can be made up of convolutional or linear layers.</p>
<p><figure>
  
    <img class="docimage" src="/blog/images/copied_from_nb/images/autoencoder.png" alt="" style="max-width: 400px">
    
    
</figure>
</p>
<p>To create our own dataset class in PyTorch we inherit from the torch.utils.data.Dataset class and define two main methods, the <code>__len__</code> and the <code>__getitem__</code></p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">transforms</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span>

<span class="k">class</span> <span class="nc">ImageDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    A class for creating data and augemntation pipeline</span>
<span class="sd">    """</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">glob_pattern</span><span class="p">:</span><span class="nb">str</span><span class="p">,</span> <span class="n">patchsize</span><span class="p">:</span><span class="nb">int</span><span class="p">):</span>
        <span class="sd">"""</span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        glob_pattern: this pattern must expand </span>
<span class="sd">            to a list of RGB images in PNG format. </span>
<span class="sd">            For eg. "/data/train/cat/*.png"</span>
<span class="sd">            </span>
<span class="sd">        patchsize: the size you want to crop</span>
<span class="sd">            the image to</span>

<span class="sd">        """</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">image_paths_list</span> <span class="o">=</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="n">glob_pattern</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">patchsize</span> <span class="o">=</span> <span class="n">patchsize</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># denotes size of data</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">image_paths_list</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">image</span><span class="p">):</span>
        <span class="c1"># convert to RGB if image is B/W</span>
        <span class="k">if</span> <span class="n">image</span><span class="o">.</span><span class="n">mode</span> <span class="o">==</span> <span class="s1">'L'</span><span class="p">:</span>
            <span class="n">image</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="s1">'RGB'</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data_transforms</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span><span class="n">transforms</span><span class="o">.</span><span class="n">RandomCrop</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">patchsize</span><span class="p">),</span>
                                                   <span class="n">transforms</span><span class="o">.</span><span class="n">RandomHorizontalFlip</span><span class="p">(),</span>
                                                   <span class="n">transforms</span><span class="o">.</span><span class="n">RandomVerticalFlip</span><span class="p">(),</span>
                                                   <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">()])</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">data_transforms</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
        <span class="c1"># generates one sample of data</span>
        <span class="n">image</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">image_paths</span><span class="p">[</span><span class="n">index</span><span class="p">])</span>
        <span class="n">image</span><span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">image</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Transforms">
<a class="anchor" href="#Transforms" aria-hidden="true"><span class="octicon octicon-link"></span></a>Transforms<a class="anchor-link" href="#Transforms"> </a>
</h3>
<p>Image processing operations using torchvision.transforms like cropping and resizing are done on the PIL Images and then they are converted to Tensors. The last transform which is transforms.ToTensor() seperates the the PIL Image into 3 channels (R,G,B) and scales its elements to the range (0,1).</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>A transform one observes a lot in Computer Vision based data pipelines is data normalization.</p>
<div class="highlight"><pre><span></span><span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">],</span>
                     <span class="n">std</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">])</span>
</pre></div>
<p>If you're wondering where do these mean and std values come from, the answer is, the <a href="http://www.image-net.org/">ImageNet dataset</a>. It's a huge dataset of 14 million images and most pre-trained models are originally trained on this. The above values are the channel-wise mean and std of all the images in the dataset. So whenever you import a pre-trained model from torchvision, make sure you apply the normalization based on the statistics of the dataset that the model was trained on. Hence, the pipeline can be summarized as</p>

<pre><code>Image --&gt; Crop/Resize --&gt; ToTensor --&gt; Normalize

</code></pre>
<p>To read more about why we normalize our data, read my blog post on this <a href="https://adityassrana.github.io/blog/theory/2020/08/26/Weight-Init.html">here</a></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Tranforms-functional-API">
<a class="anchor" href="#Tranforms-functional-API" aria-hidden="true"><span class="octicon octicon-link"></span></a>Tranforms functional API<a class="anchor-link" href="#Tranforms-functional-API"> </a>
</h3>
<p>The functional API is stateless and you can directly pass all the necessary arguments. Whereas torchvision.transforms are classes initialized with some default parameters unless specified.</p>
<div class="highlight"><pre><span></span><span class="c1"># Class-based. Define once and use multiple times</span>
<span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span> <span class="n">std</span><span class="o">=</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">))</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="c1"># Functional. Pass parameters each time</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">TF</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span> <span class="n">std</span><span class="o">=</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">))</span>
</pre></div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The functional API is very useful when transforming your data and target with the same random values, e.g. random cropping</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torchvision.transforms.functional</span> <span class="k">as</span> <span class="nn">TF</span> <span class="c1">#it's not tensorflow :p</span>
<span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">RandomCrop</span><span class="o">.</span><span class="n">get_params</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">output_size</span><span class="o">=</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">))</span>
<span class="n">image</span> <span class="o">=</span> <span class="n">TF</span><span class="o">.</span><span class="n">crop</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span>
<span class="n">mask</span> <span class="o">=</span> <span class="n">TF</span><span class="o">.</span><span class="n">crop</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>It also allows us to perform identical transforms on both image and target</p>
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">image</span><span class="p">,</span> <span class="n">mask</span><span class="p">):</span>
    <span class="c1"># Resize</span>
    <span class="n">resize</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">520</span><span class="p">,</span> <span class="mi">520</span><span class="p">))</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">resize</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">resize</span><span class="p">(</span><span class="n">mask</span>

<span class="c1"># Random horizontal flipping</span>
<span class="k">if</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">:</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">TF</span><span class="o">.</span><span class="n">hflip</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">TF</span><span class="o">.</span><span class="n">hflip</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>

<span class="c1"># Random vertical flipping</span>
<span class="k">if</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">:</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">TF</span><span class="o">.</span><span class="n">vflip</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">TF</span><span class="o">.</span><span class="n">vflip</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="DataLoaders">
<a class="anchor" href="#DataLoaders" aria-hidden="true"><span class="octicon octicon-link"></span></a>DataLoaders<a class="anchor-link" href="#DataLoaders"> </a>
</h3>
<p>The data is passed to the model few samples at a time as datasets are usually too big to fit entirely on the CPU/GPU.</p>
<p>For choosing an appropriate batch_size, make it as high as possible as long as you dont encounter <code>RuntimeError: CUDA out of memory</code> and as long as it's a multiple of 16.</p>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span>
                          <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span>
                          <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
                          <span class="n">num_workers</span> <span class="o">=</span> <span class="mi">4</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Data-Augmentation,-where-does-it-happen?">
<a class="anchor" href="#Data-Augmentation,-where-does-it-happen?" aria-hidden="true"><span class="octicon octicon-link"></span></a>Data Augmentation, where does it happen?<a class="anchor-link" href="#Data-Augmentation,-where-does-it-happen?"> </a>
</h3>
<p>A lot of people get confused about how data augmentation helps in increasing the size of the dataset when we're not actually creating or saving new images. The point to understand here is that data augmentation happens on the fly. Every time <code>__getitem__</code> method in the Dataset Class is called by the DataLoader, the transformations are applied.</p>
<p>When you  use the dataloader in your training loop, at the start of every epoch it supplies a new data-augemnted dataset with the augmentations applied to each element. This means at each epoch, the model will see a new variant of the dataset.</p>
<div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">():</span>
</pre></div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Kornia">
<a class="anchor" href="#Kornia" aria-hidden="true"><span class="octicon octicon-link"></span></a>Kornia<a class="anchor-link" href="#Kornia"> </a>
</h3>
<p>Another thing to note is that these operations are performed on the CPU so you need to make sure that your data processing does not become your training bottleneck when using large batchsizes. This is the time for introducing -</p>
<p><figure>
  
    <img class="docimage" src="/blog/images/copied_from_nb/images/kornia_logo.svg" alt="" style="max-width: 300px">
    
    
</figure>
</p>
<p><a href="https://github.com/kornia/kornia">Kornia</a> is a differentiable computer vision library for PyTorch that operates directly on tensors, hence letting you make full use of your GPUs.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Writing-Custom-Autograd-Functions-/-Layers">
<a class="anchor" href="#Writing-Custom-Autograd-Functions-/-Layers" aria-hidden="true"><span class="octicon octicon-link"></span></a>Writing Custom Autograd Functions / Layers<a class="anchor-link" href="#Writing-Custom-Autograd-Functions-/-Layers"> </a>
</h2>
<h3 id="Writing-your-own-ReLU">
<a class="anchor" href="#Writing-your-own-ReLU" aria-hidden="true"><span class="octicon octicon-link"></span></a>Writing your own ReLU<a class="anchor-link" href="#Writing-your-own-ReLU"> </a>
</h3>
<div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MyReLU</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">Function</span><span class="p">):</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span class="n">i</span><span class="p">):</span>
        <span class="sd">""" </span>
<span class="sd">        ctx is a context object that can be used</span>
<span class="sd">        to stash information for backward computation. </span>
<span class="sd">        You can cache arbitrary objects for use in the </span>
<span class="sd">        backward pass using the ctx.save_for_backward method.</span>
<span class="sd">        """</span>
        <span class="nb">input</span> <span class="o">=</span> <span class="n">i</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="n">ctx</span><span class="o">.</span><span class="n">save_for_backward</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">input</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">):</span>
        <span class="sd">"""</span>
<span class="sd">        In the backward pass we receive a Tensor </span>
<span class="sd">        containing the gradient of the loss wrt </span>
<span class="sd">        the output, and we need to compute the gradient </span>
<span class="sd">        of the loss wrt the input.</span>
<span class="sd">        """</span>
        <span class="nb">input</span><span class="p">,</span> <span class="o">=</span> <span class="n">ctx</span><span class="o">.</span><span class="n">saved_tensors</span>
        <span class="n">grad_input</span> <span class="o">=</span> <span class="n">grad_output</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="n">grad_input</span><span class="p">[</span><span class="nb">input</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">return</span> <span class="n">grad_input</span>
</pre></div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Understanding-Gradient-Shape">
<a class="anchor" href="#Understanding-Gradient-Shape" aria-hidden="true"><span class="octicon octicon-link"></span></a>Understanding Gradient Shape<a class="anchor-link" href="#Understanding-Gradient-Shape"> </a>
</h3>
<p><figure>
  
    <img class="docimage" src="/blog/images/copied_from_nb/images/local_gradients_backprop.png" alt="" style="max-width: 500px">
    
    
</figure>
</p>
<p>Gradient returned by the backward method of the class should have the same shape as the input to the forward method of the class, so that the gradient computed for the input after the loss.backward() step has the same shape as input and can be used to update it in the optimizer.step()</p>
<p>loss.backward() computes d(loss)/d(w) for every parameter which has requires_grad=True. They are accumulated in w.grad. And the optimizer.step() updates w using w.grad, w += -lr* x.grad</p>
<p>For more info read the posts below</p>
<ul>
<li><a href="https://adityassrana.github.io/blog/programming/pytorch/2020/09/25/Modern-PyTorch.html#Custom-Layers">PyTorch Custom Layers</a></li>
<li><a href="https://github.com/pytorch/pytorch/blob/53fe804322640653d2dddaed394838b868ce9a26/torch/autograd/_functions/pointwise.py">PyTorch Source Code Examples on Github</a></li>
<li><a href="https://pytorch.org/tutorials/beginner/examples_autograd/two_layer_net_custom_function.html">PyTorch official docs</a></li>
</ul>
<p>Avoid using in-place operations as they cause problems while back-propagation because of the way they modify the graph. As a precaution, always clone the input in the forward pass, and clone the incoming gradients before modifying them.</p>
<p>An in-place operation directly modifies the content of a given Tensor without making a copy. Inplace operations in PyTorch are always postfixed with a <em>, like .add</em>() or .scatter_(). Python operations like + = or *= are also in-place operations.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Dealing-with-non-differentiable-functions">
<a class="anchor" href="#Dealing-with-non-differentiable-functions" aria-hidden="true"><span class="octicon octicon-link"></span></a>Dealing with non-differentiable functions<a class="anchor-link" href="#Dealing-with-non-differentiable-functions"> </a>
</h3>
<p>Sometimes in your model or loss calculation you need to use functions that are non-differentiable. For calculating gradients, autograd requires all components of the graph to be differentiable. You can work around this by using a proxy function in the backward pass calculations.</p>

<pre><code>f_hard : non-differentiable
f_soft : differentiable proxy for w_hard

</code></pre>
<div class="highlight"><pre><span></span><span class="n">f_out</span> <span class="o">=</span> <span class="n">f_soft</span> <span class="o">+</span> <span class="p">(</span><span class="n">f_hard</span> <span class="o">-</span> <span class="n">f_soft</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>  <span class="c1"># in PyTorch</span>
<span class="n">f_out</span> <span class="o">=</span> <span class="n">f_soft</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">stop_grad</span><span class="p">(</span><span class="n">f_hard</span> <span class="o">-</span> <span class="n">f_soft</span><span class="p">)</span> <span class="c1"># in Tensorflow</span>
</pre></div>
<h3 id="Core-Idea">
<a class="anchor" href="#Core-Idea" aria-hidden="true"><span class="octicon octicon-link"></span></a>Core Idea<a class="anchor-link" href="#Core-Idea"> </a>
</h3>
<pre><code>y = x_backward + (x_forward - x_backward).detach()</code></pre>
<p>It gets you x_forward in the forward pass, but derivative acts as if you had x_backward</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Example">
<a class="anchor" href="#Example" aria-hidden="true"><span class="octicon octicon-link"></span></a>Example<a class="anchor-link" href="#Example"> </a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Binarizer</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">Function</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    An elementwise function that bins values</span>
<span class="sd">    to 0 or 1 depending on a threshold of 0.5,</span>
<span class="sd">    but in backward pass acts as an identity layer.</span>

<span class="sd">    Such layers are also known as </span>
<span class="sd">    straight-through gradient estimators</span>

<span class="sd">    Input: a tensor with values in range (0,1)</span>
<span class="sd">    Returns: a tensor with binary values: 0 or 1</span>
<span class="sd">    based on a threshold of 0.5</span>
<span class="sd">    Equation(1) in paper</span>
<span class="sd">    """</span>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span class="n">i</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">i</span><span class="o">&gt;</span><span class="mf">0.5</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">grad_output</span>

<span class="k">def</span> <span class="nf">bin_values</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">Binarizer</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The above function can be reimplemented with a single line in Pytorch
while maintaining differentiabilty</p>
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">bin_values</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">+</span> <span class="p">((</span><span class="n">x</span><span class="o">&gt;</span><span class="mf">0.5</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span> <span class="o">-</span> <span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Basic-Training-and--Validation-Loop">
<a class="anchor" href="#Basic-Training-and--Validation-Loop" aria-hidden="true"><span class="octicon octicon-link"></span></a>Basic Training and  Validation Loop<a class="anchor-link" href="#Basic-Training-and--Validation-Loop"> </a>
</h2>
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">loss_func</span><span class="p">,</span> <span class="n">opt</span><span class="p">,</span> <span class="n">train_dl</span><span class="p">,</span> <span class="n">valid_dl</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="c1"># Handle batchnorm / dropout</span>
        <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        <span class="c1"># print(model.training)</span>
        <span class="k">for</span> <span class="n">mini_batch</span> <span class="ow">in</span> <span class="n">train_dl</span><span class="p">:</span>
            <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">mini_batch</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_func</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

        <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="c1">#print(model.training)</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="k">for</span> <span class="n">mini_batch</span> <span class="ow">in</span> <span class="n">valid_dl</span><span class="p">:</span>
                <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">mini_batch</span><span class="p">)</span>
                <span class="c1"># log some metrics here</span>
            <span class="c1"># aggregate metrics from all batches</span>
</pre></div>
<p>Once you become more familiar with writing training and validation loops, I would recommend you to try out PyTorch Lightning <a href="https://github.com/PyTorchLightning/pytorch-lightning">PyTorch Lightning</a> , which is a great library started by <a href="https://www.williamfalcon.com/">William Falcon</a> that helps you get rid of all the PyTorch boilerplate code and instead lets you focus on the research part of your project.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Tensorboard">
<a class="anchor" href="#Tensorboard" aria-hidden="true"><span class="octicon octicon-link"></span></a>Tensorboard<a class="anchor-link" href="#Tensorboard"> </a>
</h2>
<h3 id="Installing">
<a class="anchor" href="#Installing" aria-hidden="true"><span class="octicon octicon-link"></span></a>Installing<a class="anchor-link" href="#Installing"> </a>
</h3>
<p>Install tensorboard with <code>pip install tensorboard</code></p>
<p><figure>
  
    <img class="docimage" src="/blog/images/copied_from_nb/images/tensorboard.gif" alt="">
    
    
</figure>
</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Creating-a-SummaryWriter">
<a class="anchor" href="#Creating-a-SummaryWriter" aria-hidden="true"><span class="octicon octicon-link"></span></a>Creating a SummaryWriter<a class="anchor-link" href="#Creating-a-SummaryWriter"> </a>
</h3>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch.utils.tensorboard</span> <span class="kn">import</span> <span class="n">SummaryWriter</span>
<span class="n">writer_train</span> <span class="o">=</span> <span class="n">SummaryWriter</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">experiment_dir</span><span class="p">,</span><span class="s2">"tensorboard"</span><span class="p">))</span>
</pre></div>
<h3 id="Scalars">
<a class="anchor" href="#Scalars" aria-hidden="true"><span class="octicon octicon-link"></span></a>Scalars<a class="anchor-link" href="#Scalars"> </a>
</h3>
<p>Logging statements are added at different steps in the training loop wherever you want to log something. You can track scalars, images and even histograms. You can read more about this on the official <a href="https://pytorch.org/docs/stable/tensorboard.html">PyTorch docs</a></p>
<p>Logging scalars can be as simple as</p>
<div class="highlight"><pre><span></span><span class="n">writer_train</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="s1">'train_loss'</span><span class="p">,</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">iteration</span><span class="p">)</span>
</pre></div>
<p>where iteration is the global_step_count that you can keep track of inside your training loop.</p>
<h3 id="Images">
<a class="anchor" href="#Images" aria-hidden="true"><span class="octicon octicon-link"></span></a>Images<a class="anchor-link" href="#Images"> </a>
</h3>
<p>We'll use <code>make_grid</code> to create a grid of images directly from tensors so that we can plot them together.</p>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torchvision.utils</span> <span class="kn">import</span> <span class="n">make_grid</span>

<span class="c1"># x is a tensor of Images of the shape (N,3,H,W)</span>
<span class="n">x_grid</span> <span class="o">=</span> <span class="n">make_grid</span><span class="p">(</span><span class="n">x</span><span class="p">[:</span><span class="mi">5</span><span class="p">],</span><span class="n">nrow</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">writer_train</span><span class="o">.</span><span class="n">add_image</span><span class="p">(</span><span class="s1">'train/original_images'</span><span class="p">,</span><span class="n">x_grid</span><span class="p">,</span> <span class="n">iteration</span><span class="p">)</span>
</pre></div>
<h3 id="Launch">
<a class="anchor" href="#Launch" aria-hidden="true"><span class="octicon octicon-link"></span></a>Launch<a class="anchor-link" href="#Launch"> </a>
</h3>
<p>To visualize what you've logged, launch a tensorboard instance from the terminal by entering <code>tensorboard --logdir .</code> in the directory where you have logged your experiments.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Inference">
<a class="anchor" href="#Inference" aria-hidden="true"><span class="octicon octicon-link"></span></a>Inference<a class="anchor-link" href="#Inference"> </a>
</h2>
<p>To make predictions out of your trained model, make sure you feed data in the right format.</p>
<p>Input Tensor Format : (batch_size, channels, height, width). The model and the convolutional layers expect the input tensor to be of the shape (N,C,H,W), so when feeding an image/images to the model, add a dimension for batching.</p>
<p>Converting from img--&gt;numpy representation and feeding the model gives an error because the input is in ByteTensor format. Only float operations are supported for conv-like operations. So add an extra step after numpy conversion -</p>
<div class="highlight"><pre><span></span><span class="n">img</span> <span class="o">=</span> <span class="n">img</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="s1">'torch.DoubleTensor'</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Saving-and-Loading-Models">
<a class="anchor" href="#Saving-and-Loading-Models" aria-hidden="true"><span class="octicon octicon-link"></span></a>Saving and Loading Models<a class="anchor-link" href="#Saving-and-Loading-Models"> </a>
</h2>
<p>PyTorch saves a model as a state_dict and the extension used is .pt</p>
<div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">PATH</span> <span class="o">=</span> <span class="s1">'latest_checkpoint.pt'</span><span class="p">)</span>
</pre></div>
<p>Sometimes you add new layers to your model which which were not present in the model you saved as checkpoint. In such a case set the <code>strict</code> keyword to False</p>
<div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">()</span>
<span class="n">checkpoint</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">'latest_checkpoint.pt'</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">,</span> <span class="n">strict</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
<p>On Loading a model, if it shows a message like this, it means there were no missing keys and everything went well ( it's not an error ).</p>

<pre><code>IncompatibleKeys(missing_keys=[], unexpected_keys=[])</code></pre>
<p>Keyboard interrupt and saving the last state of a model if you need to stop the experiment mid-way of training:</p>
<div class="highlight"><pre><span></span><span class="k">try</span><span class="p">:</span>
    <span class="c1"># training code here</span>
<span class="k">except</span> <span class="ne">KeyboardInterrupt</span><span class="p">:</span>
    <span class="c1"># save model here</span>
</pre></div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Extra-Resources">
<a class="anchor" href="#Extra-Resources" aria-hidden="true"><span class="octicon octicon-link"></span></a>Extra Resources<a class="anchor-link" href="#Extra-Resources"> </a>
</h2>
<ul>
<li><a href="https://github.com/Kaixhin/grokking-pytorch/blob/master/README.md">Grokking PyTorch</a></li>
<li><a href="https://github.com/vahidk/EffectivePyTorch/blob/master/README.md">Effective PyTorch</a></li>
<li><a href="https://amitness.com/2020/03/python-magic-behind-pytorch">The Python Magic Behind PyTorch</a></li>
<li><a href="https://github.com/chiphuyen/python-is-cool/blob/master/README.md">Python is Cool - ChipHuyen</a></li>
<li><a href="https://github.com/IgorSusmelj/pytorch-styleguide/blob/master/README.md">PyTorch StyleGuide</a></li>
<li><a href="https://github.com/zedr/clean-code-python">Clean Code Python</a></li>
<li><a href="https://dbader.org/blog/meaning-of-underscores-in-python">Using _ in Variable Naming</a></li>
<li><a href="https://discuss.pytorch.org/t/pytorch-coding-conventions/42548">Pytorch Coding Conventions</a></li>
<li><a href="https://spandan-madan.github.io/A-Collection-of-important-tasks-in-pytorch/">Fine Tuning etc</a></li>
<li><a href="https://github.com/dsgiitr/d2l-pytorch">https://github.com/dsgiitr/d2l-pytorch</a></li>
<li><a href="https://github.com/L1aoXingyu/pytorch-beginner">https://github.com/L1aoXingyu/pytorch-beginner</a></li>
<li><a href="https://github.com/yunjey/pytorch-tutorial">https://github.com/yunjey/pytorch-tutorial</a></li>
<li><a href="https://github.com/MorvanZhou/PyTorch-Tutorial">https://github.com/MorvanZhou/PyTorch-Tutorial</a></li>
</ul>

</div>
</div>
</div>
</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="adityassrana/blog"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/blog/tutorials/2020/04/22/PyTorch-Playground.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/blog/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/blog/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/blog/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p></p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/adityassrana" target="_blank" title="adityassrana"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/adityassrana" target="_blank" title="adityassrana"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>

<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>PyTorch Tips and Tricks | fastpages</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="PyTorch Tips and Tricks" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="an little-more-than-introductory guide to help people get comfortable with PyTorch functionalities." />
<meta property="og:description" content="an little-more-than-introductory guide to help people get comfortable with PyTorch functionalities." />
<link rel="canonical" href="https://adityassrana.github.io/playground/2020/01/29/PyTorch-Tips.html" />
<meta property="og:url" content="https://adityassrana.github.io/playground/2020/01/29/PyTorch-Tips.html" />
<meta property="og:site_name" content="fastpages" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-01-29T10:41:00-06:00" />
<script type="application/ld+json">
{"description":"an little-more-than-introductory guide to help people get comfortable with PyTorch functionalities.","headline":"PyTorch Tips and Tricks","dateModified":"2020-01-29T10:41:00-06:00","datePublished":"2020-01-29T10:41:00-06:00","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://adityassrana.github.io/playground/2020/01/29/PyTorch-Tips.html"},"url":"https://adityassrana.github.io/playground/2020/01/29/PyTorch-Tips.html","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/playground/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://adityassrana.github.io/playground/feed.xml" title="fastpages" /><!-- the google_analytics_id gets auto inserted from the config file -->



<script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','//www.google-analytics.com/analytics.js','ga');ga('create','UA-57531313-5','auto');ga('require','displayfeatures');ga('send','pageview');</script>

<link rel="shortcut icon" type="image/x-icon" href="/playground/images/favicon.ico"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>PyTorch Tips and Tricks | fastpages</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="PyTorch Tips and Tricks" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="an little-more-than-introductory guide to help people get comfortable with PyTorch functionalities." />
<meta property="og:description" content="an little-more-than-introductory guide to help people get comfortable with PyTorch functionalities." />
<link rel="canonical" href="https://adityassrana.github.io/playground/2020/01/29/PyTorch-Tips.html" />
<meta property="og:url" content="https://adityassrana.github.io/playground/2020/01/29/PyTorch-Tips.html" />
<meta property="og:site_name" content="fastpages" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-01-29T10:41:00-06:00" />
<script type="application/ld+json">
{"description":"an little-more-than-introductory guide to help people get comfortable with PyTorch functionalities.","headline":"PyTorch Tips and Tricks","dateModified":"2020-01-29T10:41:00-06:00","datePublished":"2020-01-29T10:41:00-06:00","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://adityassrana.github.io/playground/2020/01/29/PyTorch-Tips.html"},"url":"https://adityassrana.github.io/playground/2020/01/29/PyTorch-Tips.html","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

<link href="https://unpkg.com/@primer/css/dist/primer.css" rel="stylesheet" />
<link rel="stylesheet" href="//use.fontawesome.com/releases/v5.0.7/css/all.css"><link type="application/atom+xml" rel="alternate" href="https://adityassrana.github.io/playground/feed.xml" title="fastpages" /><!-- the google_analytics_id gets auto inserted from the config file -->



<script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','//www.google-analytics.com/analytics.js','ga');ga('create','UA-57531313-5','auto');ga('require','displayfeatures');ga('send','pageview');</script>



<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head><body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/playground/">fastpages</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/playground/about/">About Me</a><a class="page-link" href="/playground/search/">Search</a><a class="page-link" href="/playground/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">PyTorch Tips and Tricks</h1><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-01-29T10:41:00-06:00" itemprop="datePublished">
        Jan 29, 2020
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      5 min read
    
</span></p>

    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <h3 id="pytorch-and-its-modules">PyTorch and its Modules</h3>

<ol>
  <li>
    <p>Variables are now deprecated. Tensors can use Autograd directly.</p>
  </li>
  <li>
    <p>The forward function in the NN module defines how to get the output from the NN.
the nn.module() has a __ call function</p>
  </li>
</ol>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="n">NN</span><span class="p">()</span>
<span class="n">model</span><span class="p">(</span><span class="n">local_batch</span><span class="p">)</span><span class="c1">#which calls net.forward(local_batch)
</span></code></pre></div></div>

<ol>
  <li>
    <p>Input: (N,C,H,W). The model and the convolutional layers expect the input tensor to be in this format, so when feeding an image/images to the model, add a dimension for batching.</p>
  </li>
  <li>
    <p>Converting from img–&gt;numpy representation and feeding  the model gives an error because the input is in ByteTensor format. Only float operations are supported for conv-like operations.</p>
  </li>
</ol>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">img</span> <span class="o">=</span> <span class="n">img</span><span class="o">.</span><span class="nb">type</span><span class="p">(</span><span class="s">'torch.DoubleTensor'</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="dataset-and-dataloader-shenanigans">Dataset and DataLoader Shenanigans</h3>

<ol>
  <li>Create a dictionary: partition[‘train’] and partition[‘validation’].</li>
  <li>Save and Read the paths from textfiles using <code class="highlighter-rouge">ls /* /* .png &gt; train_path.txt</code></li>
  <li>For getting the number of images use <code class="highlighter-rouge">ls /* /* .png | wc -l</code></li>
  <li>Order of Transform, image processing like crops and resize should be done on the PIL Image and not the tensor
    <ul>
      <li>Crop/Resize–&gt;toTensor–&gt;Normalize</li>
    </ul>
  </li>
  <li>
    <p>the transforms.ToTensor() or TF.to_tensor(functional version of the same command) separates the PIL Image into 3 channels (R,G,B), converts it to the range (0,1). You can multiply by 255 to get the range (0,255.</p>
  </li>
  <li>Using transforms.Normalize(mean=[_ ,_ ,_ ],std = [_ ,_ ,_ ]) subtracts the mean and divides by the standard deviation. It is <strong>important</strong> to apply the specified mean and std when using a <strong>pre-trained model</strong>. This will normalize the image in the range [-1,1]. To get the original image back use</li>
</ol>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">image</span> <span class="o">=</span> <span class="p">((</span><span class="n">image</span> <span class="o">*</span> <span class="n">std</span><span class="p">)</span> <span class="o">+</span> <span class="n">mean</span><span class="p">)</span>
</code></pre></div></div>

<p>For example, when using a model trained on ImageNet it is common to apply the transformation</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="p">[</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">],</span>
                     <span class="n">std</span><span class="o">=</span><span class="p">[</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">])</span>
</code></pre></div></div>
<p>For image tensors with values in [0, 1] this transformation will standardize it so that the mean of the data should be ~0 and the std ~1. This is also known as a standard score or z-score in the literature and usually helps in training.</p>

<ol>
  <li>Data Augmentation happens at the step below. At this point __getitem__ method in the Dataset Class is called, and the transformations are applied.</li>
</ol>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">():</span>
</code></pre></div></div>
<ol>
  <li>torchvision.transforms vs torchvision.transforms.functional.</li>
</ol>

<p>The functional API is statelessand you can directly pass all the necessary arguments.</p>

<p>Whereas torchvision.transforms are classes, initialized with some default parameters unless specified.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Class-based. Define once and use multiple times
</span><span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span> <span class="n">std</span><span class="o">=</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">))</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="c1"># Functional. Pass parameters each time
</span><span class="n">data</span> <span class="o">=</span> <span class="n">TF</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span> <span class="n">std</span><span class="o">=</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">))</span>
</code></pre></div></div>

<ol>
  <li>The functional API is very useful when transforming your data and target with the same random values, e.g. random cropping:</li>
</ol>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">RandomCrop</span><span class="o">.</span><span class="n">get_params</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">output_size</span><span class="o">=</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">))</span>
<span class="n">image</span> <span class="o">=</span> <span class="n">TF</span><span class="o">.</span><span class="n">crop</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span>
<span class="n">mask</span> <span class="o">=</span> <span class="n">TF</span><span class="o">.</span><span class="n">crop</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span>

</code></pre></div></div>
<p>Functional API also allows us to perform identical transform on both image and target</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">image</span><span class="p">,</span> <span class="n">mask</span><span class="p">):</span>
    <span class="c1"># Resize
</span>    <span class="n">resize</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">520</span><span class="p">,</span> <span class="mi">520</span><span class="p">))</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">resize</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">resize</span><span class="p">(</span><span class="n">mask</span>

<span class="c1"># Random horizontal flipping
</span><span class="k">if</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">:</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">TF</span><span class="o">.</span><span class="n">hflip</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">TF</span><span class="o">.</span><span class="n">hflip</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>

<span class="c1"># Random vertical flipping
</span><span class="k">if</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">:</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">TF</span><span class="o">.</span><span class="n">vflip</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">TF</span><span class="o">.</span><span class="n">vflip</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>

</code></pre></div></div>
<ol>
  <li>Example Dataset Class:</li>
</ol>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="kn">import</span> <span class="nn">torchvision</span>
<span class="kn">import</span> <span class="nn">torchvision.transforms.functional</span> <span class="k">as</span> <span class="n">TF</span> <span class="c1">#it's not tensorflow
</span><span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">transforms</span>

<span class="k">class</span> <span class="nc">Image_Train_Dataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span> <span class="c1">#inherit from Dataset class and overrride the methods __len__ and __getitem__
</span>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">image_paths</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">list_id</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">image_paths_list</span><span class="p">,</span><span class="s">'r'</span><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">()</span><span class="o">.</span><span class="n">splitlines</span><span class="p">()</span>
        
    <span class="k">def</span> <span class="nf">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1">#return size of the Dataset
</span>        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">list_id</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">image</span><span class="p">):</span>
        <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">RandomCrop</span><span class="o">.</span><span class="n">get_params</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">output_size</span><span class="o">=</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span><span class="mi">256</span><span class="p">))</span><span class="c1">#allows us to apply the same crop on semantic segmentation if it's used
</span>        <span class="n">image</span> <span class="o">=</span> <span class="n">TF</span><span class="o">.</span><span class="n">crop</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span>
        <span class="n">image</span> <span class="o">=</span> <span class="n">TF</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span><span class="n">image</span><span class="p">,</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span><span class="mi">128</span><span class="p">))</span>
        <span class="n">image</span> <span class="o">=</span> <span class="n">TF</span><span class="o">.</span><span class="n">to_tensor</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">image</span>

    <span class="k">def</span> <span class="nf">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
        <span class="c1">#generates one sample of data
</span>        <span class="n">image</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="nb">open</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">list_id</span><span class="p">[</span><span class="n">index</span><span class="p">])</span>
        <span class="k">if</span> <span class="n">image</span><span class="o">.</span><span class="n">mode</span> <span class="o">==</span> <span class="s">'L'</span><span class="p">:</span>
            <span class="n">image</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="s">'RGB'</span><span class="p">)</span>
        <span class="n">image</span><span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">image</span>

    <span class="k">def</span> <span class="nf">load_img_data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">index</span><span class="p">):</span><span class="c1">#for making inference easier
</span>        <span class="n">image</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="nb">open</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">list_id</span><span class="p">[</span><span class="n">index</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">image</span>

    <span class="k">def</span> <span class="nf">load_tensor_data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">index</span><span class="p">):</span>
        <span class="n">image</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="nb">open</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">list_id</span><span class="p">[</span><span class="n">index</span><span class="p">])</span>
        <span class="n">image</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">image</span>
</code></pre></div></div>

<h3 id="writing-your-own-custom-autograd-functions">Writing your own custom Autograd Functions</h3>

<ol>
  <li>
    <p><a href="https://github.com/pytorch/pytorch/blob/53fe804322640653d2dddaed394838b868ce9a26/torch/autograd/_functions/pointwise.py">PyTorch Examples for Reference Github</a></p>
  </li>
  <li>
    <p><a href="https://pytorch.org/tutorials/beginner/examples_autograd/two_layer_net_custom_function.html">PyTorch official docs</a></p>
  </li>
  <li>
    <p>Gradient returned by the class should have the same shape as the input to the class, to be able to update the input in the optimizer.step() function.</p>
  </li>
  <li>
    <p>Avoid using in-place operations as they cause problems while back-propagation because the way they modify the graph. As a precaution, always clone the input in the forward pass, and clone the incoming gradients before modifying them.</p>
  </li>
</ol>

<p>An in-place operation directly modifies the content of a given Tensor without making a copy. Inplace operations in PyTorch are always postfixed with a <em>, like .add</em>() or .scatter_(). Python operations like + = or *= are also inplace operations.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">grad_input</span> <span class="o">=</span> <span class="n">grad_output</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
<span class="k">return</span> <span class="n">grad_input</span>
</code></pre></div></div>

<p>Example</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">MyReLU</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">Function</span><span class="p">):</span>

    <span class="o">@</span><span class="nb">staticmethod</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span class="n">i</span><span class="p">):</span>
        <span class="nb">input</span> <span class="o">=</span> <span class="n">i</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="s">""" ctx is a context object that can be used
        to stash information for backward computation. You can cache arbitrary
        objects for use in the backward pass using the ctx.save_for_backward method.
        """</span>
        <span class="n">ctx</span><span class="o">.</span><span class="n">save_for_backward</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">input</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="o">@</span><span class="nb">staticmethod</span>
    <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">):</span>
        <span class="s">"""
        In the backward pass we receive a Tensor containing the gradient of the loss
        with respect to the output, and we need to compute the gradient of the loss
        with respect to the input.
        """</span>
        <span class="nb">input</span><span class="p">,</span> <span class="o">=</span> <span class="n">ctx</span><span class="o">.</span><span class="n">saved_tensors</span>
        <span class="n">grad_input</span> <span class="o">=</span> <span class="n">grad_output</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="n">grad_input</span><span class="p">[</span><span class="nb">input</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">return</span> <span class="n">grad_input</span>

</code></pre></div></div>

<p>Dealing with non-differentiable functions:</p>

<p>w_hard : non-differentiable
w_soft : differentiable proxy for w_hard</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">w_bar</span> <span class="o">=</span> <span class="n">w_soft</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">stop_grad</span><span class="p">(</span><span class="n">w_hard</span> <span class="o">-</span> <span class="n">w_soft</span><span class="p">)</span> <span class="c1">#in tensorflow
</span><span class="n">w_bar</span> <span class="o">=</span> <span class="n">w_soft</span> <span class="o">+</span> <span class="p">(</span><span class="n">w_hard</span> <span class="o">-</span> <span class="n">w_soft</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>  <span class="c1">#in PyTorch
</span></code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>It gets you x_forward in the forward pass, but derivative acts as if you had x_backward
````
y = x_backward + (x_forward - x_backward).detach()
````
</code></pre></div></div>

<p>loss.backward() computes d(loss)/d(w) for every parameter which has requires_grad=True. They are accumulated in w.grad. And the optimizer.step() updates w using w.grad, w += -lr* x.grad</p>

<h3 id="saving-and-loading-models">Saving and Loading Models</h3>

<p>Python saves models as a state_dict. You may use either of the two ways</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span><span class="s">'final-contours-branch{}.pt'</span><span class="o">.</span><span class="nb">format</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">expname</span><span class="p">))</span>
<span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">({</span><span class="s">'epoch'</span><span class="p">:</span><span class="n">epoch</span><span class="p">,</span><span class="s">'model_state_dict'</span><span class="p">:</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span><span class="s">'optimizer_state_dict'</span><span class="p">:</span><span class="n">optimizer</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span><span class="s">'loss'</span><span class="p">:</span><span class="n">train_loss</span><span class="p">},</span><span class="s">'resume_training.tar'</span><span class="p">)</span>
</code></pre></div></div>

<p>On Loading a model, if it shows a message like this, it means there were no missing keys.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>IncompatibleKeys(missing_keys=[], unexpected_keys=[])
</code></pre></div></div>
<p>Use this when you have added new layers to the architecture which were not present in the model you saved as checkpoint</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">trained_dict</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s">'checkpoint.pt'</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">reducio_binarizer</span><span class="o">.</span><span class="n">Reducio</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">trained_dict</span><span class="p">,</span> <span class="n">strict</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

</code></pre></div></div>

<p>Keyboard interrupt and saving the last state of a model:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">try</span><span class="p">:</span>
    <span class="c1"># training code here
</span><span class="k">except</span> <span class="nb">KeyboardInterrupt</span><span class="p">:</span>
    <span class="c1"># save model here
</span></code></pre></div></div>

<h3 id="learning-rate-schedulers">Learning Rate Schedulers</h3>

<p>Change LR with increasing epochs. Read <a href="https://pytorch.org/docs/stable/_modules/torch/optim/lr_scheduler.html">Reduce LR on Plateau</a></p>

<h3 id="useful-links">Useful Links</h3>
<ol>
  <li><a href="https://dbader.org/blog/meaning-of-underscores-in-python">Using _ in Variable Naming</a></li>
  <li><a href="https://discuss.pytorch.org/t/pytorch-coding-conventions/42548">Pytorch Coding Conventions</a></li>
  <li><a href="https://spandan-madan.github.io/A-Collection-of-important-tasks-in-pytorch/">Fine Tuning etc</a></li>
</ol>

  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="fastai/fastpages"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/playground/2020/01/29/PyTorch-Tips.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/playground/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/playground/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/playground/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>An easy to use blogging platform with support for Jupyter Notebooks.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/fastai" title="fastai"><svg class="svg-icon grey"><use xlink:href="/playground/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/fastdotai" title="fastdotai"><svg class="svg-icon grey"><use xlink:href="/playground/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
